---
output:
  pdf_document: default
  html_document: default
---
|                                                                         |
|------------------------------------------------------------------------|
| title: " SCRIPT FOR CORRELATION-ASSOCIATION LAB for STAT 4/652 " |
| author: "Anna Panorska"                                                |STATS WORK for CORRELATION LECTURE '                            |
| output:                                                                 |
| html_document:                                                          |
| df_print: paged                                                         |

NOTE: This file contains R work for the graphs and examples for correlation-association lab. 

We start with importing the data we will work with: fire.csv, iqsize, and iqlead. All these files were used and described in the previous weeks.
```{r}
### IMPORT data set: fire.csv #############
 
fire<- read.csv("/Users/Documents/ania/teaching/452_652/452Spring2023/Week 3 Goodness of fIT/lab GoF/fire.csv")
 
### IMPORT data set: iqsize.csv #############

 iqsize<- read.csv("/Users/Documents/ania/teaching/452_652/452Spring2023/Week 3 Goodness of fIT/lab GoF/iqsize.csv")
 
iqlead<- read.csv("/Users/Documents/ania/teaching/452_652/452Spring2023/Week 2 EDA/Lab material/IQLEADtxt.csv")
#summary(iqlead)
```

We start with the work on examples of association 
First example: perfect association, monotonic, but not linear.
We will generate values of x-variable, then compute values of y-variable using a function (raising x to the fifth power).

```{r}
x<-seq(from= -2, to = 2, length=50)
y<-x^5

#Plot figure in report
  plot(x,y)
```
Sometimes we need the graph to be exported out of R in some format, like pdf. To do that we can write the following:

```{r}
  #Plot figure into a file
  pdf(file="Cor1.pdf")
  plot(x,y)
  dev.off()
  
```
  We will now compute all correlation coefficients for this generated data. The "cat" command will print to the screen as you see below. The command "round(x, n)" rounds number x to n decimal places.
  
```{r}  
  pc<-round(cor(x, y, method="pearson"), 2)
  cat("Pearson correlation=", pc, "\n")
  sc<-round(cor(x, y, method="spearman"), 2)
  cat("Spearman correlation=", sc, "\n")
  kc<-round(cor(x, y, method="kendall"), 2)
  cat("Kendall correlation=", kc, "\n")
```
Second example: perfect association, not monotonic, so not linear. This time we compute y-variable as the square of the x-variable. We will get a plot in the output, as well as exported to a pdf file (in the working directory). Finally we compute the values of all correlation coefficients.

```{r}
x<-seq(from= -2, to = 2, length=50)
y<-x^2

#Plot figure in report
  plot(x,y)

  #Plot figure in file
  pdf(file="Cor2.pdf")
  plot(x,y)
  dev.off()
  
  pc<-round(cor(x, y, method="pearson"), 3)
  cat("Pearson correlation=", pc, "\n")
  sc<-round(cor(x, y, method="spearman"), 3)
  cat("Spearman correlation=", sc, "\n")
  kc<-round(cor(x, y, method="kendall"), 3)
  cat("Kendall correlation=", kc, "\n")
```
Testing the association between IQP and LEAD exposure: we will use Pearson correlation first. 

We will start with a scatter plot of the two variables.
```{r}
#Plot figure in file
  pdf(file="CorYRS12.pdf")
  plot(iqlead$IQP,iqlead$YEAR2)
  dev.off()
```
Then, we compute the Pearson correlation and test if it is equal to zero (two sided alternative). We will use a 0.05 significance level.

The hypotheses we test are:

Ho: Pearson correlation between IQP and LEAD level in year 2 is zero. 

Ha: Pearson correlation between IQP and LEAD level in year 2 is not zero. 

```{r}
pc<-round(cor(iqlead$IQP,iqlead$YEAR2, method="pearson"), 3)
  cat("Pearson correlation=", pc, "\n")
  cor.test(iqlead$IQP,iqlead$YEAR2, method="pearson")
```
Decision: Since the p-value = 0.07874 > 0.05, then we do not reject Ho.
Conclusion: Pearson correlation between IQP and blood lead level in year 2 is not significantly different from zero.

We now move the the analysis of the fire data for any associations. We will start with plotting a "matrix plot" of scatterplots. This plot shows scatterplots of all pairs of the variables in the data set.

```{r}
require(graphics)
pairs(fire)
```
It seems from the scatterplots, that there is a linear association between "Acres" and "Acres per fire". There is a weaker association between "Acres" burnt in a month and the "Number" of fires in that month.

We now test if there is a significant linear association between "Acres" and "Acres per fire", and between "Acres" burnt in a month and the "Number" of fires. We will use all three measures of association.

The tests for the association between "Acres" and "Acres per fire" are for the following hypotheses.

Ho: Pearson/Spearman/Kendall correlation between "Acres" and "Acres per fire" is zero. 

Ha: Pearson/Spearman/Kendall correlation between "Acres" and "Acres per fire" is not zero. 

```{r}
cor.test(fire$Acres,fire$AcresFire, method="pearson")$p.value
cor.test(fire$Acres,fire$AcresFire, method="spearman")
cor.test(fire$Acres,fire$AcresFire, method="kendall")
```
We can conclude, that all the measures of association between "Number" and "Acres per fire" are significantly different than zero.

If I wanted to see only the p-value, I would do this:

```{r}
cor.test(fire$Acres,fire$AcresFire, method="pearson")$p.value
```
Check the help file for "cor.test" and what are the values (there is a list of values, and we can access the elements of that list one by one).

Now we check the association between "Number" and "Acres". 
The tests for the association between "Number" and "Acres" are for the following hypotheses.

Ho: Pearson/Spearman/Kendall correlation between "Number" and "Acres" is zero. 

Ha: Pearson/Spearman/Kendall correlation between "Number" and "Acres" is not zero. 

```{r}
cor.test(fire$Acres,fire$Number, method="pearson")$p.value
cor.test(fire$Acres,fire$Number, method="spearman")
cor.test(fire$Acres,fire$Number, method="kendall")
```
We can conclude, that all the measures of association between "Number" and "Acres" are significantly different than zero.

Next exercise: Check the impact of outliers on the three measures of correlation.
We will generate data for this.

```{r}
# Set Seed of random number generator
set.seed(4444)

# Generate random data
# First, create some normally distributed correlated data for the x1 values
x1 <- rnorm(200)

```
Then, generate y1 values as a function of x1 plus some normal error term: y1 = 0.6x1+error. We start with the error having mean zero and the same variability as x1.

```{r}
y1 <- rnorm(200) + .6 * x1
```

Second, add a major outlier to the generated raw data, like this:
```{r}
x2 <- c(x1, 14)
y2 <- c(y1, 14)
```
c(x1, 14) is a vector of data where the first coordinates are x1 and the last one is 14. Take a look at the following example:

```{r}
x<-c(1, 2, 3)
x
c(x, 15)
```

Now plot  both data sets and compute the Pearson and Spearman correlations.

```{r}
par(mfrow=c(2,2))
plot(x1, y1, main="Raw no outlier")
plot(x2, y2, main="Raw with outlier")

plot(rank(x1), rank(y1), main="Rank no outlier")
plot(rank(x2), rank(y2), main="Rank with outlier")

# Calculate correlations on both datasets
pc1<-round(cor(x1, y1, method="pearson"), 2)
cat("Pearson on raw data=", pc1, "\n")
ps1<-round(cor(x1, y1, method="spearman"), 2)
cat("Spearman on raw data", ps1,"\n")
pc2<-round(cor(x2, y2, method="pearson"), 2)
cat("Pearson on data with outlier", pc2, "\n")
ps2<-round(cor(x2, y2, method="spearman"), 2)
cat("Spearman on data with outlier",ps2, "\n")
```
You can see that the outlier did not affect the Spearman  correlation. We say that Spearman correlation is robust to outliers. Pearson correlation is impacted by outliers, it is not robust to outliers.

Now, we change the variability of the error term to a smaller one. we repeat the above exercise, but compute y1 using normal with a smaller sd.

```{r}

set.seed(4444)

x1 <- rnorm(200)
y1 <- rnorm(200, mean=0, sd=0.2) + .6 * x1
x2 <- c(x1, 14)
y2 <- c(y1, 14)

par(mfrow=c(2,2))
plot(x1, y1, main="Raw no outlier")
plot(x2, y2, main="Raw with outlier")

plot(rank(x1), rank(y1), main="Rank no outlier")
plot(rank(x2), rank(y2), main="Rank with outlier")

pc1<-round(cor(x1, y1, method="pearson"), 2)
cat("Pearson on raw data=", pc1, "\n")
ps1<-round(cor(x1, y1, method="spearman"), 2)
cat("Spearman on raw data", ps1,"\n")
pc2<-round(cor(x2, y2, method="pearson"), 2)
cat("Pearson on data with outlier", pc2, "\n")
ps2<-round(cor(x2, y2, method="spearman"), 2)
cat("Spearman on data with outlier",ps2, "\n")

```
Now, we change the position of the outlier. 
```{r}

set.seed(4444)

x1 <- rnorm(200)
y1 <- rnorm(200, mean=0, sd=0.2) + .6 * x1
x2 <- c(x1, 1)
y2 <- c(y1, 14)

par(mfrow=c(2,2))
plot(x1, y1, main="Raw no outlier")
plot(x2, y2, main="Raw with outlier")

plot(rank(x1), rank(y1), main="Rank no outlier")
plot(rank(x2), rank(y2), main="Rank with outlier")

pc1<-round(cor(x1, y1, method="pearson"), 2)
cat("Pearson on raw data=", pc1, "\n")
ps1<-round(cor(x1, y1, method="spearman"), 2)
cat("Spearman on raw data", ps1,"\n")
pc2<-round(cor(x2, y2, method="pearson"), 2)
cat("Pearson on data with outlier", pc2, "\n")
ps2<-round(cor(x2, y2, method="spearman"), 2)
cat("Spearman on data with outlier",ps2, "\n")

```
